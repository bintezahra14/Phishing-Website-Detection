{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i8WjdQfq6_o"
      },
      "source": [
        "Course: ITAI 2277 ‚Äì AI Capstone Project\n",
        "\n",
        "Binte Zahra\n",
        "\n",
        "Instructor: Sitaram Ayyagari"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9WBwrJgo_b4"
      },
      "source": [
        "# Gmail-Integrated Phishing Detector with Reinforcement Learning\n",
        "This project builds an AI-powered security tool that connects to a live Gmail inbox, scans emails for phishing threats using GPT-4o and VirusTotal, and improves over time by learning from user feedback."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IhfDjl41pN_d"
      },
      "source": [
        "## Cell 1: Setup & Environment\n",
        "#### What we did:\n",
        "Installed necessary Python packages (gradio, openai, google-api-python-client) and imported core libraries for handling email data (imaplib, email), HTML parsing, and file storage (json, os).\n",
        "\n",
        "#### Why:\n",
        "We need specific libraries to communicate with external APIs (OpenAI, VirusTotal), parse complex email formats (MIME/HTML), and create the web interface.\n",
        "\n",
        "#### How:\n",
        "Used !pip install for dependencies and set up a file structure (feedback_data/) to store the \"memory\" of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r-g4Ujo0WMJA",
        "outputId": "279b06a7-0917-4be8-da50-55baac838f63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Environment Ready.\n"
          ]
        }
      ],
      "source": [
        "# CELL 1: SETUP & IMPORTS\n",
        "!pip install -q gradio openai requests google-auth-oauthlib google-auth-httplib2 google-api-python-client\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import imaplib\n",
        "import email as email_lib\n",
        "import html\n",
        "import requests\n",
        "import openai\n",
        "import gradio as gr\n",
        "from email.header import decode_header\n",
        "from getpass import getpass\n",
        "\n",
        "# Setup Storage\n",
        "FEEDBACK_DIR = \"feedback_data\"\n",
        "os.makedirs(FEEDBACK_DIR, exist_ok=True)\n",
        "CORRECTIONS_JSON = \"user_corrections.json\"\n",
        "\n",
        "print(\"‚úÖ Environment Ready.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiNn-VFRpXba"
      },
      "source": [
        "## Cell 2: Core Logic (The Brain)\n",
        "#### What we did:\n",
        "Defined the backend functions that power the entire system.\n",
        "\n",
        "* Gmail Integration: Created a robust fetcher that logs into Gmail via IMAP, downloads the latest $N$ emails, and strips away HTML/CSS to give GPT clean text to read.\n",
        "\n",
        "* VirusTotal Integration: Built a \"Fact Checker\" that scans links against 70+ security vendors.\n",
        "\n",
        "* GPT Analysis: Created a \"Balanced Expert\" prompt that analyzes sender reputation, urgency, and context.\n",
        "\n",
        "* Reinforcement Learning (RL): Implemented a memory system (save_feedback) that records user corrections and injects them into the GPT prompt (get_learned_context) so the model doesn't repeat mistakes.\n",
        "\n",
        "* Scoring Engine: Developed a \"Max Risk\" logic engine that combines GPT's psychological analysis with VirusTotal's technical analysis.\n",
        "\n",
        "#### Why:\n",
        "* HTML Cleaning: GPT cannot read raw HTML spam accurately; it needs plain text.Consensus Rule: We ignore single VirusTotal flags to prevent false positives on marketing links (Shein, Quora).\n",
        "\n",
        "* Sanity Check: We force the numeric Score (0-100) to match the Text Verdict (SAFE/PHISHING) to prevent confusing results (e.g., \"Safe\" but score 90).\n",
        "\n",
        "#### How:\n",
        "Used Python functions with error handling. The scoring logic uses conditional overrides (e.g., if gpt_verdict == \"PHISHING\" -> force score 85)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ufIVDt2mqau",
        "outputId": "879c2af4-ab1f-4ead-d9b2-4bec3ecba894"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Logic Updated: Sanity Check Added.\n"
          ]
        }
      ],
      "source": [
        "# ==========================================\n",
        "# PASTE THIS INTO CELL 2 (Replacing previous code)\n",
        "# ==========================================\n",
        "\n",
        "import os, re, json, time, imaplib, email as email_lib, html, requests, openai\n",
        "from email.header import decode_header\n",
        "\n",
        "current_imap = None\n",
        "CORRECTIONS_FILE = \"user_corrections.json\"\n",
        "\n",
        "# --- 1. LEARNING MEMORY ---\n",
        "def save_feedback(subject, sender, actual_label):\n",
        "    try:\n",
        "        data = []\n",
        "        if os.path.exists(CORRECTIONS_FILE):\n",
        "            with open(CORRECTIONS_FILE, 'r') as f:\n",
        "                data = json.load(f)\n",
        "        new_entry = {\"subject\": subject, \"sender\": sender, \"actual_label\": actual_label}\n",
        "        data.append(new_entry)\n",
        "        with open(CORRECTIONS_FILE, 'w') as f:\n",
        "            json.dump(data[-20:], f, indent=2)\n",
        "        return len(data)\n",
        "    except: return 0\n",
        "\n",
        "def get_learned_context():\n",
        "    if not os.path.exists(CORRECTIONS_FILE): return \"\"\n",
        "    try:\n",
        "        with open(CORRECTIONS_FILE, 'r') as f:\n",
        "            data = json.load(f)\n",
        "        if not data: return \"\"\n",
        "        context = \"IMPORTANT - LEARN FROM THESE PAST MISTAKES:\\n\"\n",
        "        for item in data[-5:]:\n",
        "            context += f\"- Email from '{item['sender']}' with subject '{item['subject']}' was actually {item['actual_label']}.\\n\"\n",
        "        return context\n",
        "    except: return \"\"\n",
        "\n",
        "# --- 2. GMAIL UTILS ---\n",
        "def connect_gmail_simple(email_address, app_password):\n",
        "    try:\n",
        "        imap = imaplib.IMAP4_SSL(\"imap.gmail.com\")\n",
        "        imap.login(email_address, app_password)\n",
        "        return imap\n",
        "    except Exception as e:\n",
        "        print(f\"Connection Error: {e}\")\n",
        "        return None\n",
        "\n",
        "def clean_html(html_content):\n",
        "    clean = re.sub(r'<style.*?>.*?</style>', '', html_content, flags=re.DOTALL)\n",
        "    clean = re.sub(r'<script.*?>.*?</script>', '', clean, flags=re.DOTALL)\n",
        "    clean = re.sub(r'<[^>]+>', ' ', clean)\n",
        "    return html.unescape(clean).strip()\n",
        "\n",
        "def fetch_recent_emails(imap, max_emails):\n",
        "    try:\n",
        "        imap.select(\"INBOX\")\n",
        "        status, messages = imap.search(None, \"ALL\")\n",
        "        email_ids = messages[0].split()[-max_emails:]\n",
        "        emails = []\n",
        "        for email_id in reversed(email_ids):\n",
        "            try:\n",
        "                status, msg_data = imap.fetch(email_id, \"(RFC822)\")\n",
        "                msg = email_lib.message_from_bytes(msg_data[0][1])\n",
        "                subject, encoding = decode_header(msg.get(\"Subject\", \"No Subject\"))[0]\n",
        "                if isinstance(subject, bytes): subject = subject.decode(encoding or \"utf-8\", errors=\"ignore\")\n",
        "\n",
        "                body = \"\"\n",
        "                if msg.is_multipart():\n",
        "                    for part in msg.walk():\n",
        "                        if part.get_content_type() == \"text/plain\":\n",
        "                            body = part.get_payload(decode=True).decode(\"utf-8\", errors=\"ignore\"); break\n",
        "                        elif part.get_content_type() == \"text/html\":\n",
        "                            body = clean_html(part.get_payload(decode=True).decode(\"utf-8\", errors=\"ignore\"))\n",
        "                else:\n",
        "                    body = clean_html(msg.get_payload(decode=True).decode(\"utf-8\", errors=\"ignore\"))\n",
        "\n",
        "                urls = re.findall(r'https?://[^\\s<>\"]+', body)\n",
        "                emails.append({\n",
        "                    \"subject\": subject,\n",
        "                    \"from\": msg.get(\"From\", \"Unknown\"),\n",
        "                    \"date\": msg.get(\"Date\", \"\"),\n",
        "                    \"body\": body[:2000],\n",
        "                    \"url\": urls[0] if urls else \"\"\n",
        "                })\n",
        "            except: continue\n",
        "        return emails\n",
        "    except: return []\n",
        "\n",
        "# --- 3. ANALYSIS LOGIC ---\n",
        "def check_virustotal(url):\n",
        "    \"\"\"Check URL with FALSE POSITIVE protection\"\"\"\n",
        "    if not url: return 0, \"No URL found.\"\n",
        "    api = os.environ.get('VT_API_KEY')\n",
        "    if not api: return 0, \"‚ö†Ô∏è VT Key Missing\"\n",
        "    try:\n",
        "        id_resp = requests.post('https://www.virustotal.com/api/v3/urls', headers={'x-apikey': api}, data={'url': url}).json()\n",
        "        rep = requests.get(f\"https://www.virustotal.com/api/v3/analyses/{id_resp['data']['id']}\", headers={'x-apikey': api}).json()\n",
        "\n",
        "        stats = rep['data']['attributes']['stats']\n",
        "        mal = stats['malicious']\n",
        "        susp = stats['suspicious']\n",
        "\n",
        "        if mal >= 2: return 100, f\"üö® DANGEROUS: {mal} vendors confirmed malware.\"\n",
        "        elif mal == 1: return 45, \"‚ö†Ô∏è CAUTION: 1 vendor flagged this (could be false positive).\"\n",
        "        elif susp > 1: return 50, \"‚ö†Ô∏è SUSPICIOUS: Multiple suspicious flags.\"\n",
        "        return 0, \"‚úÖ CLEAN URL\"\n",
        "    except: return 0, \"‚ö†Ô∏è Scan Failed\"\n",
        "\n",
        "def ask_gpt(subject, body, sender, url):\n",
        "    learned_context = get_learned_context()\n",
        "    prompt = f\"\"\"You are a cybersecurity expert.\n",
        "{learned_context}\n",
        "Sender: {sender}\n",
        "Subject: {subject}\n",
        "Body Snippet: {body[:1500]}\n",
        "Link: {url}\n",
        "\n",
        "Analyze for PHISHING vs SPAM vs SAFE.\n",
        "RULES:\n",
        "1. SAFE: Known brands (Shein, Khan Academy, Quora, LinkedIn) sending standard promos.\n",
        "2. SPAM: Annoying marketing, but harmless.\n",
        "3. PHISHING: Impersonation, credential theft, urgent threats.\n",
        "\n",
        "OUTPUT FORMAT:\n",
        "VERDICT: [PHISHING/SPAM/SAFE]\n",
        "SCORE: [0-100] (0=Safe, 100=Danger)\n",
        "REASON: [Short explanation]\n",
        "\"\"\"\n",
        "    try:\n",
        "        res = openai.chat.completions.create(model=\"gpt-4o-mini\", messages=[{\"role\": \"user\", \"content\": prompt}], temperature=0)\n",
        "        content = res.choices[0].message.content\n",
        "\n",
        "        # 1. Parse raw output\n",
        "        score = 50\n",
        "        if \"SCORE:\" in content: score = int(re.search(r'SCORE:\\s*(\\d+)', content).group(1))\n",
        "\n",
        "        reason = content.split(\"REASON:\")[1].strip() if \"REASON:\" in content else \"Analysis failed\"\n",
        "\n",
        "        verdict = \"SAFE\"\n",
        "        if \"PHISHING\" in content.upper(): verdict = \"PHISHING\"\n",
        "        elif \"SPAM\" in content.upper(): verdict = \"SPAM\"\n",
        "\n",
        "        # --- FIX: SANITY CHECK (Force Score to match Verdict) ---\n",
        "        # GPT sometimes confuses \"Score 90\" with \"90% Safe\". We must correct this.\n",
        "\n",
        "        if verdict == \"SAFE\" and score > 30:\n",
        "            score = 10  # Force score down if Verdict is Safe\n",
        "\n",
        "        elif verdict == \"PHISHING\" and score < 70:\n",
        "            score = 85  # Force score up if Verdict is Phishing\n",
        "\n",
        "        elif verdict == \"SPAM\":\n",
        "            score = 50  # Keep Spam in the middle\n",
        "\n",
        "        return verdict, score, reason\n",
        "    except Exception as e: return \"ERROR\", 0, str(e)\n",
        "\n",
        "def analyze_logic(subject, body, url, sender):\n",
        "    gpt_verdict, gpt_score, gpt_reason = ask_gpt(subject, body, sender, url)\n",
        "    vt_score, vt_reason = check_virustotal(url)\n",
        "\n",
        "    # 1. Base Logic\n",
        "    final_score = max(gpt_score, vt_score)\n",
        "\n",
        "    # 2. Logic Overrides\n",
        "    if gpt_verdict == \"SAFE\" and vt_score < 50:\n",
        "        final_score = gpt_score  # Trust GPT on Safety if VT is weak\n",
        "\n",
        "    if gpt_verdict == \"PHISHING\" and final_score < 75:\n",
        "        final_score = 85        # Trust GPT on Phishing\n",
        "\n",
        "    # 3. Final Labels\n",
        "    if final_score < 30: final_verdict = \"‚úÖ SAFE\"\n",
        "    elif final_score < 70: final_verdict = \"‚ö†Ô∏è SPAM / SUSPICIOUS\"\n",
        "    else: final_verdict = \"üö® PHISHING\"\n",
        "\n",
        "    report = f\"\"\"\n",
        "# {final_verdict}\n",
        "**Threat Score:** {final_score}/100\n",
        "\n",
        "### ü§ñ GPT Analysis\n",
        "* **Verdict:** {gpt_verdict}\n",
        "* **Score:** {gpt_score}/100\n",
        "* **Reason:** {gpt_reason}\n",
        "\n",
        "### ü¶† VirusTotal\n",
        "* {vt_reason}\n",
        "\"\"\"\n",
        "    return report, final_score, {\"subject\": subject, \"sender\": sender}\n",
        "\n",
        "print(\"‚úÖ Logic Updated: Sanity Check Added.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBpU0Cr4qMu4"
      },
      "source": [
        "## Cell 3: Security & API Keys\n",
        "\n",
        "#### What we did:\n",
        "Created a secure input method for OpenAI and VirusTotal API keys.\n",
        "\n",
        "#### Why:\n",
        "Hardcoding API keys is a security risk. Using getpass ensures keys are entered securely per session and not saved in the notebook file.\n",
        "\n",
        "#### How:\n",
        "Used the getpass library to accept inputs without echoing characters to the screen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JpS2y9VWVwl",
        "outputId": "3a607786-0f7e-4924-abd7-fb51bdb59fed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter OpenAI API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n",
            "Enter VirusTotal API Key: ¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑¬∑\n"
          ]
        }
      ],
      "source": [
        "# CELL 3: KEYS\n",
        "openai.api_key = getpass(\"Enter OpenAI API Key: \")\n",
        "os.environ['VT_API_KEY'] = getpass(\"Enter VirusTotal API Key: \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eEPe160qdps"
      },
      "source": [
        "## Cell 4: The Interface (Frontend)\n",
        "#### What we did:\n",
        "Built a modern web dashboard using Gradio.\n",
        "\n",
        "* State Management: Used gr.State to store fetched emails in memory, ensuring that clicking \"Scan Email #1\" actually scans the correct email, not an old one.\n",
        "\n",
        "* Feedback Loop: Added \"Mark as Safe\" and \"Mark as Phishing\" buttons that instantly update the JSON memory file.\n",
        "\n",
        "* Controls: Added a slider to fetch between 5-15 emails (to manage API quotas).\n",
        "\n",
        "#### Why:\n",
        "A simple script is hard to use. A GUI allows users to browse their actual inbox, view threat scores visually, and easily provide training feedback.\n",
        "\n",
        "#### How:\n",
        "Wired Python backend functions to Gradio UI components (Button, Dataframe, Slider) using event listeners (.click())."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "dA1Yrxe_Wjod",
        "outputId": "10963a03-8da2-4e69-8614-347d244f3374"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-1935708439.py:2: DeprecationWarning: The 'theme' parameter in the Blocks constructor will be removed in Gradio 6.0. You will need to pass 'theme' to Blocks.launch() instead.\n",
            "  with gr.Blocks(title=\"Phishing Detector\", theme=gr.themes.Soft()) as demo:\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://d23c84415a183a3348.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://d23c84415a183a3348.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# CELL 4: UI WITH REINFORCEMENT LEARNING\n",
        "with gr.Blocks(title=\"Phishing Detector\", theme=gr.themes.Soft()) as demo:\n",
        "\n",
        "    # State Storage\n",
        "    emails_state = gr.State([])\n",
        "    current_email_context = gr.State({}) # Stores current email info for feedback\n",
        "\n",
        "    gr.Markdown(\"# üõ°Ô∏è Precision Phishing Detector + RL\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column(scale=1):\n",
        "            gr.Markdown(\"### 1. Connect\")\n",
        "            user = gr.Textbox(label=\"Gmail Address\")\n",
        "            pwd = gr.Textbox(label=\"App Password\", type=\"password\")\n",
        "            login_btn = gr.Button(\"Login\", variant=\"primary\")\n",
        "            login_status = gr.Textbox(label=\"Status\")\n",
        "\n",
        "            gr.Markdown(\"### 2. Fetch Emails\")\n",
        "            num_emails = gr.Slider(5, 15, value=5, step=1, label=\"Fetch Count\")\n",
        "            fetch_btn = gr.Button(\"Fetch Emails\", variant=\"secondary\")\n",
        "\n",
        "        with gr.Column(scale=2):\n",
        "            gr.Markdown(\"### 3. Select & Scan\")\n",
        "            email_table = gr.Dataframe(headers=[\"Index\", \"Subject\", \"Sender\", \"Date\"], interactive=False)\n",
        "\n",
        "            with gr.Row():\n",
        "                idx_input = gr.Number(label=\"Email Index (0=Newest)\", precision=0)\n",
        "                scan_btn = gr.Button(\"üîç Scan This Email\", variant=\"primary\")\n",
        "\n",
        "            report_out = gr.Markdown()\n",
        "            score_out = gr.Slider(0, 100, label=\"Threat Score\")\n",
        "\n",
        "            # --- FEEDBACK SECTION ---\n",
        "            with gr.Group():\n",
        "                gr.Markdown(\"### üéì Reinforcement Learning (Teach the Model)\")\n",
        "                with gr.Row():\n",
        "                    fb_safe = gr.Button(\"‚úÖ Wrong! Mark as SAFE\")\n",
        "                    fb_phish = gr.Button(\"üö® Wrong! Mark as PHISHING\")\n",
        "                fb_msg = gr.Textbox(label=\"Learning Status\", interactive=False)\n",
        "\n",
        "    # --- LOGIC ---\n",
        "    def login(u, p):\n",
        "        global current_imap\n",
        "        current_imap = connect_gmail_simple(u, p)\n",
        "        return \"‚úÖ Connected\" if current_imap else \"‚ùå Failed\"\n",
        "\n",
        "    def fetch_and_store(n):\n",
        "        if not current_imap: return None, []\n",
        "        raw = fetch_recent_emails(current_imap, n)\n",
        "        disp = [[i, e['subject'], e['from'], e['date']] for i, e in enumerate(raw)]\n",
        "        return disp, raw\n",
        "\n",
        "    def scan_specific_email(idx, stored_emails):\n",
        "        if not stored_emails: return \"Fetch first.\", 0, {}\n",
        "        try:\n",
        "            i = int(idx)\n",
        "            if i < 0 or i >= len(stored_emails): return \"Invalid Index\", 0, {}\n",
        "            e = stored_emails[i]\n",
        "            # Returns Report, Score, and CONTEXT (Sender/Subject) for feedback\n",
        "            return analyze_logic(e['subject'], e['body'], e['url'], e['from'])\n",
        "        except Exception as x: return str(x), 0, {}\n",
        "\n",
        "    # --- FEEDBACK HANDLERS ---\n",
        "    def learn_safe(ctx):\n",
        "        if not ctx: return \"Scan an email first.\"\n",
        "        count = save_feedback(ctx['subject'], ctx['sender'], \"SAFE\")\n",
        "        return f\"‚úÖ Learned! '{ctx['subject'][:20]}...' is SAFE. (Memory: {count} items)\"\n",
        "\n",
        "    def learn_phish(ctx):\n",
        "        if not ctx: return \"Scan an email first.\"\n",
        "        count = save_feedback(ctx['subject'], ctx['sender'], \"PHISHING\")\n",
        "        return f\"üö® Learned! '{ctx['subject'][:20]}...' is PHISHING. (Memory: {count} items)\"\n",
        "\n",
        "    # --- WIRING ---\n",
        "    login_btn.click(login, [user, pwd], login_status)\n",
        "    fetch_btn.click(fetch_and_store, num_emails, [email_table, emails_state])\n",
        "\n",
        "    # Scanning updates the Report, Score, and saves Context for the feedback buttons\n",
        "    scan_btn.click(scan_specific_email, [idx_input, emails_state], [report_out, score_out, current_email_context])\n",
        "\n",
        "    # Feedback buttons read the Context\n",
        "    fb_safe.click(learn_safe, current_email_context, fb_msg)\n",
        "    fb_phish.click(learn_phish, current_email_context, fb_msg)\n",
        "\n",
        "demo.launch(share=True, debug=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFUB4L2Uqy9k"
      },
      "source": [
        "# Project Logic Flow\n",
        "* Fetch: User connects Gmail -> Script pulls raw emails -> Cleans HTML -> Stores in Memory.\n",
        "\n",
        "* Scan: User selects email -> Script checks Link in VirusTotal + Sends Text to GPT (with past mistakes included).\n",
        "\n",
        "* Score: Script compares GPT verdict vs. VirusTotal verdict -> Applies \"Safety Overrides\" -> Outputs Final Score.\n",
        "\n",
        "* Learn: User marks prediction \"Wrong\" -> Script saves correction to JSON -> GPT sees this correction next time."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_JE0l3Eh77R"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}